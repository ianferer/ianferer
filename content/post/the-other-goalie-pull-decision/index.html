---
title: "The Other Goalie Pull Decision"
author: "Ian Ferer"
date: "2022-03-05"
output:
    html_document: default
    pdf_document: default
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>You just remembered that your favorite hockey team is playing tonight. You turn on the game during the first intermission to find that your team’s starting goalie has given up 3 goals on only 8 shots, putting them in a 3-0 hole after the first period. If you were the coach, what would you do? Would you leave the starter in net, or would you put in the backup goalie? You know that the starter is the better goalie on paper, but everyone has bad games now and then – is tonight one of those games? How confident are you in your answer? Even if the starter is having an off night, does the backup really give you a better chance to win? If so, how much better? Is the game already out of reach anyway? Answering these questions is important, but maybe the most important question is this: how exactly do you plan to answer them?</p>
<p>This is the main goal of this project – we want to develop a systematic approach to answering all of these questions about our starting goalie. How can we model a hockey game to appropriately capture all of the uncertainty that exists when trying to judge a goalie’s performance within a single game, <em>especially</em> when we want to make this judgment while the game is still in progress? Additionally, when creating this model, we need to consider what information we need to make a decision, and whether or not we can obtain it in real time. Then, how do we devise a decision rule? That is, given the model and the necessary inputs to the model, how do we interpret and use the model output to make a binary decision (leave in the starter or put in the backup)?</p>
<p>This article will focus primarily on creating a <em>theoretical</em> model of a hockey game that allows us to make inferences about a goalie’s performance within a single game – while that game is in progress – by accounting for all the uncertainty that goes into judging a goaltender on fewer than 60 minutes worth of goaltending. For this reason, this article will involve more probability theory than application, but the basic statistical theory and modeling ideas discussed here will serve as the foundation for all future parts of this project.</p>
</div>
<div id="data-modeling-assumptions" class="section level2">
<h2>Data &amp; Modeling Assumptions</h2>
<p>Because we want to make decisions about goalies in real time, it is important to make sure that our model is dependent only on data we can obtain in real time. While it would be much better to use statistics like expected goals to make judgments about our goalie’s performance, we may not always be able to obtain accurate numbers quickly enough to make an immediate decision. Therefore, while we know that not all shots are identical, for the purposes of making quick decisions, we will assume that all shots on goal have an equal probability of becoming goals, and that all shots on goal are independent of each other (this is also clearly not true, but we are trying to create a simple, tractable model, not a perfect model). It is not difficult to record counts of both goals against and shots on goal against as they occur, so we will consider these two statistics when attempting to evaluate goalies in real time. Restricting our statistics to only goals allowed and shots on goal faced also allows this model to be extended to other leagues where expected goals are not fully developed, such as professional women’s leagues, junior and college leagues, and international play.</p>
<p>Then, given our assumptions and the data that we have available for this particular problem, there is a natural method of evaluating goalie performance. If we assume that each shot a goalie faces has an independent and equal probability of resulting in a goal, then we can evaluate goalies by what we believe this goal probability to be. That is, for a particular game, we will assume that a goalie will save each shot they face with a fixed probability <span class="math inline">\(\theta \in [0, 1]\)</span>, and that the value of <span class="math inline">\(\theta\)</span> is dependent only on the goalie. All decisions will therefore be based (at least in part) on our beliefs about <span class="math inline">\(\theta\)</span>. Note that we assume <span class="math inline">\(\theta\)</span> to be fixed for a particular game, but it is not assumed to be fixed from game to game (if it were fixed from game to game, this problem would be far less interesting). Note also that this differs from our usual understanding of save percentage: instead of <span class="math inline">\(\theta\)</span> simply representing the proportion of shots saved by the goalie over the course of the game, here we are treating <span class="math inline">\(\theta\)</span> as a parameter representing the true probability that a goalie saves each given shot they face. For this reason, we will refer to <span class="math inline">\(\theta\)</span> as a goalie’s <em>save probability</em>.</p>
<p>In summary, we are making the following assumptions about a hockey game:</p>
<ul>
<li>Every shot a goalie faces will be saved with probability <span class="math inline">\(\theta\)</span>, and will result in a goal with probability <span class="math inline">\(1 - \theta\)</span>.</li>
<li>These shots on goal are independent of each other.</li>
<li>The value of <span class="math inline">\(\theta\)</span> is entirely dependent on the goalie facing these shots, and <span class="math inline">\(\theta\)</span> is fixed for the goalie for a given game, but is not necessarily fixed from game to game.</li>
</ul>
<p>Under these assumptions, we can model the process of a goalie facing shots on goal as a sequence of Bernoulli trials, where each trial has success probability <span class="math inline">\(1 - \theta\)</span>, with success defined to be a shot resulting in a goal. Then, given the number of shots faced <span class="math inline">\(n\)</span> and the goalie’s save probability <span class="math inline">\(\theta\)</span>, the number of goals allowed by the goalie <span class="math inline">\(X\)</span> follows a binomial distribution with <span class="math inline">\(n\)</span> trials and success probability <span class="math inline">\(1 - \theta\)</span>. That is, the probability of a goalie allowing exactly <span class="math inline">\(x\)</span> goals on <span class="math inline">\(n\)</span> shots, for <span class="math inline">\(x \in \left\{ 0, \dots, n \right\}\)</span>, is given by</p>
<p><span class="math display">\[ \Pr \left( X = x \mid \theta \right) = \binom{n}{x} \left( 1 - \theta \right)^{x} \theta^{n - x} \]</span></p>
<p>If we knew the value of <span class="math inline">\(\theta\)</span> for both our starting goalie and our backup goalie for a given game, then we would know which goalie would give us the better chance to win, and this problem would already be solved. Therefore, we will take <span class="math inline">\(\theta\)</span> to be unknown, and we will need to perform some sort of statistical inference about the value of <span class="math inline">\(\theta\)</span> in order to represent the reality of our decision-making process. While there are several ways to do this, it will be most helpful to think about <span class="math inline">\(\theta\)</span> in a Bayesian context.</p>
</div>
<div id="bayesian-inference" class="section level2">
<h2>Bayesian Inference</h2>
<p><strong>Note: it is not necessary to have a deep understanding of Bayes’ theorem for this project, but if you are unfamiliar with Bayes’ theorem and/or would like to better understand what it means, it may be helpful to watch some or all of the following videos from <a href="https://www.3blue1brown.com/about">3Blue1Brown</a>, as Grant does an excellent job explaining the intuition behind much of the probability theory employed here. Each video is around 10-15 minutes long, but they are well worth the time if you are new to Bayesian inference and would like to understand more about the math being done here:</strong></p>
<ol style="list-style-type: decimal">
<li><strong><a href="https://youtu.be/HZGCoVF3YvM">Bayes’ theorem</a></strong></li>
<li><strong><a href="https://youtu.be/8idr1WZ1A7Q">Probabilities of probabilities, part 1</a></strong></li>
<li><strong><a href="https://youtu.be/ZA4JkHKZM50">Probabilities of probabilities, part 2</a></strong></li>
</ol>
<p>To understand <span class="math inline">\(\theta\)</span> in the spirit of Bayesian inference, we assume a <em>prior distribution</em> <span class="math inline">\(\pi \left( \cdot \right)\)</span> on <span class="math inline">\(\theta\)</span> that represents our prior beliefs about how <span class="math inline">\(\theta\)</span> behaves. That is, we treat <span class="math inline">\(\theta\)</span> as a random quantity that is realized for each game (and is thus fixed for each game, but not from game to game), and <span class="math inline">\(\pi \left( \cdot \right)\)</span> represents the probability density according to which <span class="math inline">\(\theta\)</span> takes values. To make the inference process easier, we will assume for now that <span class="math inline">\(\theta\)</span> follows a beta distribution, which is the <em>conjugate prior distribution</em> for the binomial distribution (for the purposes of this project, all that this means is that the beta distribution makes all calculations easier when performing Bayesian inference on a probability parameter). The beta distribution is defined for <span class="math inline">\(\theta \in [0, 1]\)</span> (which is why it works well as a prior distribution for probability parameters) and is characterized by two shape parameters <span class="math inline">\(\alpha &gt; 0\)</span> and <span class="math inline">\(\beta &gt; 0\)</span>, and has probability density given by</p>
<p><span class="math display">\[ f \left( \theta \mid \alpha, \beta \right) = \frac{\theta^{\alpha - 1} \left( 1 - \theta \right)^{\beta - 1}}{\text{B} \left( \alpha, \beta \right)} \]</span></p>
<p>where <span class="math inline">\(\text{B}\)</span> is the beta function, which serves as a normalizing constant to ensure <span class="math inline">\(f\)</span> is a valid probability density. From this density, we can also find that if <span class="math inline">\(\theta \sim \text{Beta} \left( \alpha, \beta \right)\)</span>, then the expected value of <span class="math inline">\(\theta\)</span> is given by</p>
<p><span class="math display">\[ \mathbb{E} \left( \theta \right) = \frac{\alpha}{\alpha + \beta} \]</span></p>
<p>For Bayesian inference, we can choose <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> however we want in order to reflect our original beliefs about <span class="math inline">\(\theta\)</span> (we will explore some ways to choose a prior later). As an example, if we have no prior beliefs about <span class="math inline">\(\theta\)</span>, then we may want to assume that it is uniformly distributed on the interval <span class="math inline">\([0, 1]\)</span>, in which case we can choose <span class="math inline">\(\alpha = \beta = 1\)</span>, which gives a beta distribution with mean <span class="math inline">\(\mathbb{E} \left( \theta \right) = 0.50\)</span>.</p>
<p>In the context of our situation where <span class="math inline">\(\theta\)</span> represents a save probability, it will be helpful to think of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> in terms of a goalie facing shots on goal. Essentially, when we choose <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we are assuming that we have <em>already watched</em> the goalie save <span class="math inline">\(\alpha\)</span> shots and allow <span class="math inline">\(\beta\)</span> goals on a total of <span class="math inline">\(\alpha + \beta\)</span> shots, before the game begins (<span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> do not have to be integers, but when thinking about what they mean it will be helpful to think of them as integers). Therefore, if we choose smaller values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we will be more uncertain about <span class="math inline">\(\theta\)</span>, as we are assuming less information, but then each shot we <em>actually</em> observe will contribute more to our beliefs about <span class="math inline">\(\theta\)</span> in the current game. On the other hand, if we assume larger values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we will be more certain about <span class="math inline">\(\theta\)</span> before the game, and each shot we observe will contribute less to our beliefs about <span class="math inline">\(\theta\)</span> in the current game. Furthermore, this should give some more context to the expected value of the beta distribution. For example, if we choose <span class="math inline">\(\alpha = 10\)</span> and <span class="math inline">\(\beta = 1\)</span>, then we are assuming that we’ve seen the goalie make 10 saves on 11 shots, for an observed save percentage of <span class="math inline">\(10/11 \approx 0.9091\)</span> – this is exactly the mean of our prior distribution.</p>
<p>For now, assume that we have chosen <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> to represent our prior beliefs. We can then summarize our model so far as follows:</p>
<ul>
<li>Given the true value of <span class="math inline">\(\theta \in [0, 1]\)</span>, the number of goals allowed <span class="math inline">\(X\)</span> on <span class="math inline">\(n\)</span> shots on goal (assuming <span class="math inline">\(n\)</span> is known) is distributed according to <span class="math inline">\(X \mid \theta \sim \text{Binomial} \left( n, 1 - \theta \right)\)</span></li>
<li>The goalie’s save probability <span class="math inline">\(\theta\)</span> is distributed according to <span class="math inline">\(\theta \sim \text{Beta} \left( \alpha, \beta \right)\)</span></li>
</ul>
<p>In order to make inferences about <span class="math inline">\(\theta\)</span> as the game progresses, we can observe successive values of <span class="math inline">\(X\)</span> with known <span class="math inline">\(n\)</span>, and then we can update our prior distribution <span class="math inline">\(\pi \left( \cdot \right)\)</span> in light of these values of <span class="math inline">\(X\)</span> using Bayes’ theorem:</p>
<p><span class="math display">\[ \pi \left( \theta \mid x \right) = \frac{\Pr \left( X = x \mid \theta \right) \pi \left( \theta \right)}{\int_{\Theta} \Pr \left( X = x \mid \theta \right) \pi \left( \theta \right) \ d \theta} \]</span></p>
<p>In this formula:</p>
<ul>
<li><span class="math inline">\(\pi \left( \theta \mid x \right)\)</span> is the <em>posterior density</em> of <span class="math inline">\(\theta\)</span> given an observed value of <span class="math inline">\(X = x\)</span></li>
<li><span class="math inline">\(\Pr \left( X = x \mid \theta \right)\)</span> is the probability of allowing <span class="math inline">\(X = x\)</span> goals on <span class="math inline">\(n\)</span> shots, given the values of <span class="math inline">\(n\)</span> and <span class="math inline">\(\theta\)</span></li>
<li><span class="math inline">\(\pi \left( \theta \right)\)</span> is the prior density of <span class="math inline">\(\theta\)</span></li>
<li><span class="math inline">\(\Theta = [0, 1]\)</span> is the set of all possible values of <span class="math inline">\(\theta\)</span></li>
</ul>
<p>Without going into the details of the computation, we can find that the posterior density of <span class="math inline">\(\theta\)</span> given <span class="math inline">\(x\)</span> is given by</p>
<p><span class="math display">\[ \pi \left( \theta \mid x \right) = \frac{\theta^{\alpha + n - x - 1} \left( 1 - \theta \right)^{\beta + x - 1}}{\text{B} \left( \alpha + n - x, \beta + x \right)} \]</span></p>
<p>Note that this is exactly the probability density of a <span class="math inline">\(\text{Beta} \left( \alpha + n - x, \beta + x \right)\)</span> distribution, which means that</p>
<p><span class="math display">\[ \theta \mid X = x \sim \text{Beta} \left( \alpha + n - x, \beta + x \right) \]</span></p>
<p>In practice, this simply means that we add the number of saves on <span class="math inline">\(n\)</span> shots to our prior choice of <span class="math inline">\(\alpha\)</span> and we add the number of goals allowed on <span class="math inline">\(n\)</span> shots to our prior choice of <span class="math inline">\(\beta\)</span> to get our posterior distribution, which is also a beta distribution.</p>
<p>To get an idea of what it actually means to update our beliefs after each successive shot on goal, suppose that for a given hockey game, the starting goalie’s true save probability is <span class="math inline">\(\theta = 0.900\)</span>. Suppose we begin by assuming a uniform prior on the interval <span class="math inline">\([0, 1]\)</span>, so <span class="math inline">\(\alpha = \beta = 1\)</span>, and over the course of the game the goalie faces <span class="math inline">\(n = 50\)</span> shots on goal. We can simulate the results of each of these 50 shots and iteratively compute the new posterior distribution given the result of each shot. The following graph displays the updated probability densities after every 10 shots, including the initial choice of prior <span class="math inline">\(\text{Beta} \left( 1, 1 \right)\)</span>. The dashed line indicates the true value of <span class="math inline">\(\theta = 0.900\)</span>:</p>
<p><img src="staticUpdated%20Beta%20Distributions%20(Static)-1.png" width="672" /></p>
<p>Note that as we observe more shots, the densities become narrower and more concentrated around 0.900 (which we know to be the true value of <span class="math inline">\(\theta\)</span>), meaning that as we gain more information about the goalie’s performance, we become more confident about our beliefs in <span class="math inline">\(\theta\)</span>, and most of the mass of the posterior distribution becomes concentrated around the true value of <span class="math inline">\(\theta\)</span>. However, it should be noted that the distribution after all 50 shots peaks at a value greater than <span class="math inline">\(\theta = 0.900\)</span>, so clearly our Bayesian updating method doesn’t perfectly estimate <span class="math inline">\(\theta\)</span> after just 50 shots (however, as <span class="math inline">\(n\)</span> increases indefinitely, we’d expect our posterior distribution to converge to a single point mass at the true value of <span class="math inline">\(\theta\)</span>). In any case, we can see that the posterior distribution still indicates that <span class="math inline">\(\theta = 0.900\)</span> is very much within the realm of reason for our goalie, so while the estimation process isn’t perfect, it is good enough for our purposes, and more importantly, it captures uncertainty to a good degree when we can never be truly certain about <span class="math inline">\(\theta\)</span>.</p>
<p>It may also be helpful to animate this graph by plotting the updated distribution after each shot on goal. The animation below displays the process of updating the density after each shot faced. The black line indicates the true value of <span class="math inline">\(\theta = 0.900\)</span>, while the magenta line indicates the mean of the updated distribution:</p>
<p><img src="staticUpdated%20Beta%20Distributions%20(Animated)-1.gif" /><!-- --></p>
<p>On the surface, this animation should make clear what is happening when we iteratively compute posterior distributions. Early on, the mass of the distribution is spread out, but we can see it become more concentrated over time to indicate increasing confidence in our posterior beliefs. Recall from the static graph that our theoretical goalie allowed 4 goals on 50 shots, and note that we can clearly observe the density shift to the left four times – these shifts occur when the four goals are allowed. After every other shot, the mass of the density shifts toward 1, and as we approach 50 shots faced, the posterior mean appears to be converging to the true value of <span class="math inline">\(\theta\)</span> (although it does increase slightly beyond the true value).</p>
<p>Essentially, this updating scheme provides a way to quantify our confidence in our estimation of <span class="math inline">\(\theta\)</span>. For low values of <span class="math inline">\(n\)</span>, there is still a lot of uncertainty in our judgments about <span class="math inline">\(\theta\)</span>, but every shot gives us more information, so as we continue to observe more and more shots on goal, we should begin to believe that <span class="math inline">\(\theta\)</span> falls into a smaller and smaller range with higher probability, informally quantifying our confidence in both our goalie and in our judgments about their save probability in the current game. It would therefore be reasonable, at least in theory, to use this method of Bayesian inference to codify our judgments about our starting goalie as the game progresses.</p>
</div>
<div id="creating-a-decision-rule" class="section level2">
<h2>Creating a Decision Rule</h2>
<p>Now that we have established a way to model our beliefs about our goalies, there are still two questions we need to answer in order to create a decision rule:</p>
<ul>
<li>How should we choose the values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> for our initial prior distribution?</li>
<li>Given the posterior distribution of <span class="math inline">\(\theta\)</span>, exactly <em>how</em> do we convert the distribution into a decision rule with a binary choice?</li>
</ul>
<p>Because of the theoretical nature of our decision process to this point, we will focus more on the <em>process</em> of crafting a decision rule using this model, rather than using data to create an optimal decision rule – this will be explored in future parts.</p>
<div id="choosing-a-prior" class="section level3">
<h3>Choosing a Prior</h3>
<p>While we could choose any positive values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> for our initial prior, we would like them to reflect a reasonable opinion that a coach could have at the beginning of a hockey game. Here we will propose a few possible priors, along with the primary justification for choosing each one.</p>
<div id="uninformative-priors" class="section level4">
<h4>Uninformative Priors</h4>
<p>We have already mentioned the uniform prior on <span class="math inline">\([0, 1]\)</span>, which is equivalently characterized by the <span class="math inline">\(\text{Beta} \left( 1, 1 \right)\)</span> distribution, as a potential choice of prior. Most likely, the uniform prior is not an accurate representation of the distribution of <span class="math inline">\(\theta\)</span>, as a uniform prior would indicate that we believe that <span class="math inline">\(\Pr \left( \theta \leq 0.100 \right) = \Pr \left( \theta \geq 0.900 \right) = 0.10\)</span> – in the context of this problem, this would indicate that we believe that our starter allowing over 90% of the shots they face and our starter saving over 90% of the shots they face have equal probability of being true. While this is almost certainly not the case, we may believe that the amount of uncertainty in how our starter is going to perform on a given night is so large that we don’t want to be overconfident in our goalie’s ability for a single game. This is the main benefit of choosing an <em>uninformative prior</em> – if we believe that our goalie’s past performance has little to no effect on how they’re going to perform tonight, then we might want to choose a prior that is not biased toward any one particular outcome, such as the uniform prior that assigns equal likelihood to any possible probability in <span class="math inline">\([0, 1]\)</span>.</p>
<p>In addition, there is another uninformative prior that we might wish to use instead. The <span class="math inline">\(\text{Beta} \left( 1/2, 1/2 \right)\)</span> prior is shown on the graph below (note that the density goes to infinity at both 0 and 1, but is still a valid probability density):</p>
<p><img src="staticUninformative%20Prior-1.png" width="672" /></p>
<p>Unlike the uniform prior, this prior places most of the mass near <span class="math inline">\(\theta = 0\)</span> and <span class="math inline">\(\theta = 1\)</span>. While it would seem to be more informative than the uniform prior, if we truly knew nothing about the goalie’s save probability or the process of a goalie facing shots on goal, then we might believe that either all shots would be stopped or all shots would go in. More generally, if we are observing a process that ends with either success or failure, but we know nothing else about the process, then we might believe that the process is <em>deterministic</em> before we observe anything – that is, we might believe that the probability of success is either 1 or 0, at least until we see the process produce both success and failure. This prior may be less intuitive, since we know that shutouts are relatively rare and goalies almost certainly won’t let in every shot they face on a given night, but if we want to enter each game with no bias toward the goalie’s past performances, this is another possible choice of uninformative prior.</p>
</div>
<div id="data-driven-priors" class="section level4">
<h4>Data-Driven Priors</h4>
<p>Instead of using an uninformative prior, we could use information from previous performances to create a prior that may be more realistic in terms of what distribution a goalie’s save probability might follow. For example, we might want to use the goalie’s most recent game to inform our choice of prior. If the goalie faced <span class="math inline">\(n\)</span> shots and allowed <span class="math inline">\(x\)</span> goals, then we might want to choose <span class="math inline">\(\alpha = 1 + n - x\)</span> and <span class="math inline">\(\beta = 1 + x\)</span> – that is, we could effectively use the posterior distribution from the previous game (if we started with a uniform prior) as our new prior for the goalie’s next game. (The additional 1 in each parameter is to ensure that neither <span class="math inline">\(\alpha\)</span> nor <span class="math inline">\(\beta\)</span> is 0, as would be the case if the goalie posted a shutout in their previous game.) If we wanted to use a larger sample of data, we could also consider the goalie’s previous <span class="math inline">\(k\)</span> games (where <span class="math inline">\(k\)</span> is an arbitrary positive integer of our choice), taking the total number of saves and total number of goals allowed as <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, respectively.</p>
<p>Using this method of selecting a prior would indicate a good deal of confidence in our estimate of <span class="math inline">\(\theta\)</span>, as we would be using a full game’s worth of shots to inform our prior, instead of taking an uninformative prior (recall that larger values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> convey more confidence in our prior beliefs). However, while this would provide a more realistic prior for <span class="math inline">\(\theta\)</span>, it could also be detrimental to our end goal. As an example, if our goalie posted a 50-save shutout in their previous game, the prior for the current game could inspire overconfidence in <span class="math inline">\(\theta\)</span> being very close to 1, so if the starter then allows 2 goals on 3 shots, our posterior distribution would still be highly confident in the goalie’s ability, even though the evidence for this game quickly appears to be suggesting otherwise. Then again, if our goalie posted a shutout in their previous game, we might be willing to give them more slack in their next game. Using more than one previous game to inform a prior constructed in this way would only serve to provide more confidence in our beliefs, which would amplify both the advantages and disadvantages of choosing a prior in this way.</p>
<p>As an alternative to taking raw save and goal totals to inform our choice of prior, another possible option would be to fit a beta distribution to previously observed values of <span class="math inline">\(\theta\)</span>. Since we are assuming that <span class="math inline">\(\theta\)</span> is a random variable that is realized as a fixed value for each game a goalie plays, it may be reasonable to record the values of <span class="math inline">\(\theta\)</span> for several goalie starts and fit a beta distribution to those values. While <span class="math inline">\(\theta\)</span> is unknown for each game (since under our model assumptions we cannot ever be certain of the goalie’s true save probability), we can obtain a point estimate for <span class="math inline">\(\theta\)</span> from each game by using <em>Laplace’s rule of succession</em>, which states that if we observe <span class="math inline">\(n\)</span> shots on goal and <span class="math inline">\(x\)</span> goals and nothing else, the probability that the next shot would be saved is equal to <span class="math inline">\((n - x + 1) / (n + 2)\)</span>. In fact, this is the mean of the posterior distribution obtained if we observe <span class="math inline">\(x\)</span> goals on <span class="math inline">\(n\)</span> shots and assume a uniform prior on <span class="math inline">\(\theta\)</span>. Since we <em>can</em> observe the values of <span class="math inline">\(n\)</span> and <span class="math inline">\(x\)</span> for each goalie start, we can consider estimates of <span class="math inline">\(\theta\)</span> under the rule of succession. In the context of this problem, our estimates for <span class="math inline">\(\theta\)</span> are close to our usual understanding of save percentage, but we need to modify them in order to account for our uncertainty – we are assuming that the true value of <span class="math inline">\(\theta\)</span> is still unknown after the game ends, but typically we understand save percentage within a game to be the proportion of shots saved by the goalie, which is always known after the game ends.</p>
<p>Then, given estimates of <span class="math inline">\(\theta\)</span> (obtained via the rule of succession) from some sample of <span class="math inline">\(k\)</span> games that we have observed, denoted <span class="math inline">\(\hat{\theta}_{1}, \dots, \hat{\theta}_{k}\)</span>, we can attempt to find the values of <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> such that the <span class="math inline">\(\text{Beta} \left( \hat{\alpha}, \hat{\beta} \right)\)</span> distribution best fits the observed values of <span class="math inline">\(\hat{\theta}_{1}, \dots, \hat{\theta}_{k}\)</span>. Without getting too deep into the statistical theory, there are two main ways to fit a distribution in this way: using the method of moments, or using maximum likelihood estimation.</p>
<p>However, before fitting any distributions, we first need to obtain some data. <a href="https://moneypuck.com/">MoneyPuck.com</a> provides a dataset for download containing information about all unblocked shots beginning in the 2007-2008 season, with 124 features for each shot. For this preliminary exploration, we are only concerned with the number of shots faced and goals allowed by the <em>starting</em> goalies for each team in each game played. We will also restrict our attention to regular season games played from the 2014-2015 season through the 2020-2021 season, and we will only consider shots faced and goals allowed in regulation time (since overtime hockey is played at a far different pace from regulation hockey). From this information, we can compute an estimated save probability for each goalie start. The smoothed density of these estimated save probabilities is shown below:</p>
<p><img src="staticSmoothed%20SVP%20Density-1.png" width="672" /></p>
<p>Given the sample average <span class="math inline">\(\bar{x}\)</span> and the sample variance <span class="math inline">\(s^{2}\)</span> of a sample of observations drawn from a <span class="math inline">\(\text{Beta} \left( \alpha, \beta \right)\)</span> distribution, the method-of-moments estimators <span class="math inline">\(\hat{\alpha}_{\text{MM}}\)</span> and <span class="math inline">\(\hat{\beta}_{\text{MM}}\)</span> are computed by</p>
<p><span class="math display">\[\begin{align}
\hat{\alpha}_{\text{MM}} &amp;= \bar{x} \left( \frac{\bar{x} \left( 1 - \bar{x} \right)}{s^{2}} - 1 \right) \\
\hat{\beta}_{\text{MM}} &amp;= \left( 1 - \bar{x} \right) \left( \frac{\bar{x} \left( 1 - \bar{x} \right)}{s^{2}} - 1 \right)
\end{align}\]</span></p>
<p>assuming that <span class="math inline">\(\bar{x} \left( 1 - \bar{x} \right) &gt; s^{2}\)</span>. We find that <span class="math inline">\(\hat{\alpha}_{\text{MM}} \approx 21.322\)</span> and <span class="math inline">\(\hat{\beta}_{\text{MM}} \approx 2.969\)</span>. The method-of-moments density is represented by the dashed line in the plot below, along with the actual density of estimated starter save probabilities:</p>
<p><img src="staticSVP%20Density%20MM-1.png" width="672" /></p>
<p>This fitted distribution is relatively similar to the actual distribution, although the range of <span class="math inline">\(\theta\)</span> around the mode of the fitted distribution has less mass than in the actual distribution, which is made up for by the fitted density having slightly more mass in the range around <span class="math inline">\(\theta = 0.80\)</span>. For the maximum likelihood estimators of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we cannot obtain closed forms, but we can use any simple statistical software to compute <span class="math inline">\(\hat{\alpha}_{\text{MLE}} \approx 22.541\)</span> and <span class="math inline">\(\hat{\beta}_{\text{MLE}} \approx 3.165\)</span>, which gives the following distribution:</p>
<p><img src="staticSVP%20Density%20MLE-1.png" width="672" /></p>
<p>The shape of this fitted distribution appears to be slightly better than the previous fitted distribution, although the differences do not appear to be significant (as evidenced by the small differences between the values of the two estimators). For these reasons, either method of parameter estimation is likely appropriate for this exercise, although maximum likelihood estimation is typically preferred in general statistical settings.</p>
<p>It is worth noting again that this part of the project is not attempting to find an optimal prior, nor is it attempting to make any suggestions about what we should be using as a prior. With that in mind, either of the priors computed here via the method of moments or via maximum likelihood estimation are reasonable choices of prior. Neither set of estimators is perfect, but they each provide a prior that, in general, provides more confidence in our starter than an uninformative prior, but not as much confidence in our starter as simply using the raw shot and goal totals from their previous game(s). The most important thing to note is that it appears that estimated starter save probabilities do closely follow a beta distribution, and that the method of moments and maximum likelihood estimation both seem to be viable methods of creating a prior.</p>
<p>While we could simply choose the previous <span class="math inline">\(k\)</span> league-wide starter performances to create a prior in this way, which would give us a fairly large sample size of estimated starter save probabilities, it may be the case that we want to tailor our prior more closely to our team’s goalie(s). In this regard, we could also restrict our estimates <span class="math inline">\(\hat{\theta}_{k}\)</span> to either the team level or the goalie level. As an extreme example, we would likely expect the distribution of <span class="math inline">\(\theta\)</span> to be much different for a recent Vezina trophy winner compared to a rookie or aging veteran, so we may want to include only performances from our Vezina-winning goalie in fitting a prior for their next game. Conversely, we also might want to temper our expectations a bit – we know that even Vezina winners have bad games from time to time, so we may want our prior to reflect that possibility as being more likely than just the Vezina winner’s recent games might suggest, in which case we might want to include all goalie starts from across the league.</p>
<p>With all of this in mind, the upshot here is that there are several possibilities for how to use past game performances to craft a prior – the suggestions proposed here are meant to be a good baseline of possible priors that a coach could have about their goalies, but by no means do they comprise a complete list of good choices of prior.</p>
</div>
</div>
<div id="converting-the-posterior-into-a-decision-rule" class="section level3">
<h3>Converting the Posterior Into a Decision Rule</h3>
<p>Suppose now that we have chosen <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> to encode our prior beliefs, and by the previous discussion we know that if our goalie has given up <span class="math inline">\(x\)</span> goals on <span class="math inline">\(n\)</span> shots, we will be representing our current belief about their performance by a <span class="math inline">\(\text{Beta} \left( \alpha + n - x, \beta + x \right)\)</span> distribution. However, now that we have this distribution, what do we do with it? A probability density can’t make a decision for us, so we need to come up with a way to compute some information from the distribution we have, and then to convert that information into a decision. Similarly to the previous section on choosing a prior, this section is not going to be focused on optimizing a decision rule – we are simply going to discuss some ways we can manipulate the distribution we have, as well as some additional parameters we may want to consider when deciding <em>when</em> during the game we want to make a decision.</p>
<div id="really-bad-starts-rbs" class="section level4">
<h4>Really Bad Starts (RBS)</h4>
<p>Really Bad Starts, abbreviated RBS, is a statistic created by Rob Vollman (now with the Los Angeles Kings) for the <a href="http://www.hockeyabstract.com/">Hockey Abstract</a>. A goalie is credited with an RBS whenever they start a game and finish with a save percentage below 0.85 – after all, teams whose starting goalie posted an RBS won only 12.35% of the time between 2014-2015 and 2020-2021. If we restrict that to games where only one of the two starting goalies posted an RBS, the teams whose goalie posted an RBS have a win rate of only 6.89% between 2014-2015 and 2020-2021 (both of these win percentages were computed using the MoneyPuck dataset). It would therefore seem like one good way to decide if our goalie is having a bad game is by attempting to classify their game as an RBS (I briefly discussed the process of doing this in a <a href="https://twitter.com/ianferer/status/1396541656007127042?s=20&amp;t=llEIHbaDHD6H0PnmTZm6PA">Twitter thread</a> during the 2021 playoff series between the Hurricanes and Predators). Given the current posterior distribution of <span class="math inline">\(\theta\)</span> after observing <span class="math inline">\(x\)</span> goals allowed on <span class="math inline">\(n\)</span> shots, we then want to compute</p>
<p><span class="math display">\[ \Pr \left( \text{RBS} \right) = \Pr \left( \theta \leq 0.85 \right) = \int_{0}^{0.85} \pi \left( y \mid x, \alpha, \beta \right) \ d y \]</span></p>
<p>Luckily, this is not difficult to compute. However, once we have <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span>, we need to use it to make a decision. A reasonable idea would be to classify the start as an RBS (and thus pull the starter) if <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span> is greater than some threshold <span class="math inline">\(t \in [0, 1]\)</span> – but how should we choose <span class="math inline">\(t\)</span>? In order to choose <span class="math inline">\(t\)</span>, we first need to decide what the penalty should be for both types of incorrect decision. That is, if <span class="math inline">\(\Pr \left( \text{RBS} \right) \geq t\)</span>, but the goalie isn’t actually having a bad game, how should we penalize that wrong decision? What about if <span class="math inline">\(\Pr \left( \text{RBS} \right) &lt; t\)</span>, but the goalie is actually having a bad game? Assigning costs to these decisions is crucial in choosing a threshold <span class="math inline">\(t\)</span>, but there are many ways to assign costs. If we are strictly trying to maximize our chances of winning, we may decide that we’d rather incorrectly pull the goalie during a good game than incorrectly leave in the goalie during a bad game, in which case we’d choose a lower value of <span class="math inline">\(t\)</span>. If instead our job is in danger and we want to avoid making a catastrophically bad decision in the eyes of fans, media, and ownership, we might be willing to leave in the starter for a longer time, rather than making a quick judgment that could turn out incorrect, in which case we’d want <span class="math inline">\(t\)</span> to be much closer to 1. If all we are concerned with is making the right decision as much as possible, then we’d probably want to choose <span class="math inline">\(t = 0.50\)</span>, or very close to 0.50. The important thing is that there are multiple ways to choose <span class="math inline">\(t\)</span> so that our decision rule is tailored to how we want to make our goalie decisions.</p>
</div>
<div id="comparing-values-of-theta" class="section level4">
<h4>Comparing Values of <span class="math inline">\(\theta\)</span></h4>
<p>While classifying starts as good or bad based on the CDF of <span class="math inline">\(\theta\)</span> for our starter is a simple computation, decision rules crafted in that way do not take into account our beliefs about the backup goalie. As mentioned previously, we would probably consider a Vezina-winning goalie and an aging veteran backup goalie to have very different prior distributions on their save probabilities. Therefore, while we might have good reason to believe that our Vezina-winning starter is having a bad game, it could be the case that our starter having a bad game is still better than our backup having an okay game (by their respective standards). Instead of classifying the starter’s game just based on their own value of <span class="math inline">\(\theta\)</span>, we could compute the probability that the starter’s save probability is lower than the backup’s save probability. With respect to our model, if we assume prior distributions</p>
<p><span class="math display">\[\begin{align}
\theta_{S} &amp; \sim \text{Beta} \left( \alpha_{S}, \beta_{S} \right) \\
\theta_{B} &amp; \sim \text{Beta} \left( \alpha_{B}, \beta_{B} \right)
\end{align}\]</span></p>
<p>for the starting goalie and backup goalie, respectively, and we observe the starter give up <span class="math inline">\(x\)</span> goals on <span class="math inline">\(n\)</span> shots, we would then have</p>
<p><span class="math display">\[ \theta_{S} \sim \text{Beta} \left( \alpha_{S} + n - x, \beta_{S} + x \right) \]</span></p>
<p>and then we could compute</p>
<p><span class="math display">\[ \Pr \left( \theta_{S} \leq \theta_{B} \right) = \int_{0}^{1} \int_{0}^{y} \pi_{S} \left( z \mid x \right) \pi_{B} \left( y \right) \ d z \ d y \]</span></p>
<p>Similarly to before, since we know the form of <span class="math inline">\(\pi_{S} \left( \cdot \right)\)</span> and <span class="math inline">\(\pi_{B} \left( \cdot \right)\)</span>, this is not difficult to compute with the right software. We would again need to choose a threshold <span class="math inline">\(t\)</span> such that we pull the starter if <span class="math inline">\(\Pr \left( \theta_{S} \leq \theta_{B} \right) \geq t\)</span> and leave in the starter otherwise, but this can be done exactly the same way as detailed above. Of course, there are likely other reasonable ways to convert a beta distribution into a decision rule – these are only a few suggestions.</p>
</div>
<div id="other-considerations" class="section level4">
<h4>Other Considerations</h4>
<p>Assume now that we have a decision rule <span class="math inline">\(d \left( \cdot \right)\)</span> that takes as input the parameters defining the posterior distribution of <span class="math inline">\(\theta\)</span> for the starting goalie (and possibly some other arguments as well), and returns a decision either to pull the starter or leave in the starter. How should we be using it? That is, at what points during the game should we be considering a goalie change, and how should we be using game-state information to help us with this decision? Of course, we can only make a goalie change during a stoppage in play, but we almost certainly shouldn’t be considering a goalie change at every stoppage. Conventionally, we would only consider pulling the starter after a goal against or after an intermission – after all, the starter making a save would only serve to improve our judgment of them, and no other information except for goals allowed is affecting our posterior beliefs about the goalie. As for switching goalies coming out of an intermission, we may want to pull our goalie after a goal, but if there is little time left on the clock, we may choose to just wait that time out and regroup during the intermission.</p>
<p>That said, consider the following situation: our goalie gives up 3 goals in the first period, but the team in front of the goalie holds the opposition to only 7 shots on goal, while generating 16 shots on goal and scoring none. We’re likely not very confident in our goalie, but the rest of the team is playing well. We don’t want to make a quick judgment, so we leave the starter in net. However, our team scores 2 quick goals to begin the second period, and all of a sudden it’s a close game again. The last thing we want is for a bad goalie to tank this comeback before we can finish it off, so maybe we now have more to lose if a bad game from our starter winds up costing us in the end. Should we pull the starter now that we seem to have a better chance of actually winning the game? In other words, should we consult <span class="math inline">\(d \left( \cdot \right)\)</span> for a recommended decision after scoring a goal ourselves? At the very least, this (maybe uncommon) example might influence us to consult our decision rule in some less-conventional instances.</p>
<p>Additionally, we need to consider common situations where we might want to overrule the decision rule. We probably won’t ever want to pull the starter if our decision rule is telling us that they’re having a good game, so instead we’ll only consider situations where <span class="math inline">\(d \left( \cdot \right)\)</span> returns a decision to pull the starter, but we might have reason to be more conservative. A simple example would be the case where the starter gives up a goal on their first shot faced. If we choose the maximum likelihood estimators <span class="math inline">\(\hat{\alpha}_{\text{MLE}}\)</span> and <span class="math inline">\(\hat{\beta}_{\text{MLE}}\)</span> computed previously as our prior, we have <span class="math inline">\(\Pr \left( \text{RBS} \right) \approx 0.295\)</span> with just the initial prior distribution, but if the goalie allows 1 goal on 1 shot, we then have <span class="math inline">\(\Pr \left( \text{RBS} \right) \approx 0.485\)</span>. Depending on our choice of threshold <span class="math inline">\(t\)</span>, this could result in a suggested goalie switch extremely early in the game. The uncertainty in our judgment would still be extremely large, and we’d be risking a lot of earned respect and reputation if we wound up being wrong. For this reason, a good idea would be to have a minimum number of goals allowed before evaluating the starter. That said, this minimum shouldn’t be too large, as if we waited until the starter allowed 5 goals to evaluate whether they’re having a bad night, it would almost always be too late for pulling the starter to make any difference.</p>
<p>We would also probably like to consider the amount of time remaining in the game, both when there is a lot of time remaining and when the game is nearly over. We likely wouldn’t want to pull the starter 2 minutes into the game, even if they did give up a bad goal early. On the other hand, if we’re down 4-2 with 10 minutes left in the third period, and our starter allows a fifth goal, does it really matter if we make the right decision about their play? Is there any reward to pulling them this late? Furthermore, what if this is the first game of a back-to-back, and the backup on the bench is starting tomorrow night? In that situation, we might just want to punt on tonight’s game, let tomorrow’s starter rest, and hope we can salvage the second night.</p>
<p>In a similar vein, we also need to consider information beyond just our decision rule <span class="math inline">\(d \left( \cdot \right)\)</span> and some game-state data. A goalie giving up 2 goals on 4 shots in 10 minutes looks bad on the box score, but if both goals came from high-danger scoring chances, we might be willing to give the starter some leniency before pulling them in favor of the backup. This is where expected goals could come in handy – while we may not be able to obtain shot probabilities in real time, we can always consult them after the fact as a supplement to the immediate decision we can obtain from our decision rule.</p>
<p>Again: the most important thing here is the <em>process</em> behind creating the decision rule <span class="math inline">\(d \left( \cdot \right)\)</span> and then making actionable decisions, regardless of whether they agree with the output of <span class="math inline">\(d \left( \cdot \right)\)</span>. This process is <em>not</em> intended to erase the need for subjective judgment about the starting goalie – it is merely meant to supplement our decision-making process with a mathematical model that captures the volatility in the task we’re trying to accomplish, in order to hopefully help us make better-informed decisions that could help us win more hockey games.</p>
</div>
</div>
<div id="an-example-decision-rule" class="section level3">
<h3>An Example Decision Rule</h3>
<p>Given all of the components that go into creating a decision rule, it will be helpful to craft an example and illustrate how we could use it during a game. For this toy example, suppose that our usual starting goalie played last night and faced 50 shots, so the recently-signed rookie backup is playing their first game in the NHL, and we have no idea what to expect from their performance. It then seems reasonable to choose a uniform <span class="math inline">\(\text{Beta} \left( 1, 1 \right)\)</span> prior for this goalie. For our decision rule, we’re going to attempt to correctly classify whether this start will be an RBS, as it’s a slightly simpler decision method that doesn’t involve our backup (who we don’t really want to throw into action tonight, based on their workload from yesterday). We’ll also choose <span class="math inline">\(t = 0.5\)</span>, as for this one game we’re just interested in making a correct classification. However, we don’t want to destroy our rookie starter’s confidence, so we’re willing to give them 3 goals without considering pulling them. That is, we won’t consider the output from <span class="math inline">\(d \left( \cdot \right)\)</span> until the starter gives up their fourth goal (if it comes to that). Now that we’ve constructed <span class="math inline">\(d \left( \cdot \right)\)</span> and imposed some additional constraints on our decision-making process, we could have a computer on stand-by to compute <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span> after each goal allowed, but we can speed up the process a bit by creating a pull chart beforehand that considers all reasonable combinations of shots faced <span class="math inline">\(n\)</span> and goals allowed <span class="math inline">\(x\)</span>, and provides a visual indicator of whether we should be pulling the goalie at that value of <span class="math inline">\(\left( n, x \right)\)</span>. For this task – attempting to correctly classify whether the goalie will be credited with an RBS – using a <span class="math inline">\(\text{Beta} \left( 1, 1 \right)\)</span> prior, a <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span> threshold of <span class="math inline">\(t = 0.5\)</span>, and not pulling the starter until they give up 4 goals at minimum, we obtain the following pull chart:</p>
<p><img src="staticPull%20Chart%20(Binary)-1.png" width="672" /></p>
<p>It also may be the case that we don’t want to choose a threshold immediately – we may want to weigh our subjective opinion of the goalie against our current Bayesian estimate of <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span>, in which case we can also easily create a chart that colors each <span class="math inline">\(\left( n, x \right)\)</span> pair by <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span> for a goalie allowing <span class="math inline">\(x\)</span> goals on <span class="math inline">\(n\)</span> shots under our choice of prior. We then obtain the following pull chart:</p>
<p><img src="staticPull%20Chart%20(Continuous)-1.png" width="672" /></p>
<p>For this example, since we don’t want to evaluate our goalie until they’ve allowed 4 goals, we can effectively treat <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span> as 0 for any pair <span class="math inline">\(\left( n, x \right)\)</span> with <span class="math inline">\(x &lt; 4\)</span>, in which case we obtain the following pull chart, which might be easier to read and interpret under the conditions we’ve established:</p>
<p><img src="staticPull%20Chart%20(Continuous%20with%20min.%20goals)-1.png" width="672" /></p>
<p>Given the current number of shots our starter has faced and the number of goals they’ve allowed, we can then immediately look up the corresponding cells on each of these charts to obtain the decision returned by <span class="math inline">\(d \left( \cdot \right)\)</span> or the estimated value of <span class="math inline">\(\Pr \left( \text{RBS} \right)\)</span>, depending on what we choose to use. While the merits of this particular rule <span class="math inline">\(d \left( \cdot \right)\)</span> are up for debate, the simplicity of these charts allows for an easy consultation guide for a coach who has other decisions to make during a hockey game (including setting forechecking tactics, optimizing line combinations and matchups, deciding when to call a timeout, and deciding when to pull the goalie for an extra attacker, among several others). Analogous charts to these can be easily created for any choice of prior and threshold, and if we define a prior for the backup goalie as well, we can create a pull chart for the other type of decision rule proposed here, where we compute the probability that the starter is better than the backup.</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>This analysis provides a heuristic approach to judging a goalie within a single game. We’ve taken Bayesian inference – which informally amounts to updating beliefs with more information – and applied it to the evaluation of a goaltender based on a statistic that they can control. The modeling techniques presented here are in no way perfect, as several assumptions are made to simplify the game of hockey down to a sequence of Bernoulli trials that are entirely dependent on goalies. However, the goal of this part of the project is not to create a perfect tool that tells us when to pull our starting goalie for having a bad game, but instead to propose a new way of mathematically modeling and thinking about how to judge goalies during a game, as this is a tool a coach could use to influence their team’s chances of winning the game. While we typically see coaches make changes to line combinations, attempt to get favorable matchups against opponents’ lines, and optimize player usage by way of zone starts, we rarely see analogous techniques applied to optimizing goalie play – the processes introduced here are meant to be a preliminary exploration into how we might be able to do that.</p>
<p>That said, it is clear that there are several deficiencies with using only the work presented here. As explained previously, this analysis provides no evaluation of any priors or decision rules proposed. We could use a historical sample of goalie starts and attempt to find the parameters that will optimize some classification accuracy metric, such as the false pull rate, the false keep rate, the total error rate, or the log loss of our estimated probabilities, among many others. However, because this model is theoretical, there are several parameters we’d need to tune in order to find an optimal decision rule, including the prior parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, the threshold <span class="math inline">\(t\)</span>, the minimum number of goals allowed before evaluation, and even the type of decision rule. Furthermore, simply evaluating a classifier based on the correctness of the decision does not account for any time-dependence of the decision, since clearly we’d want to be rewarded more for an early correct decision than a late correct decision, and similarly penalized with incorrect decisions. There are simply too many parameters we would need to optimize over in order to find a single optimal decision rule of the types mentioned here.</p>
<p>Therefore, in order to transform this work into something more usable, we need to use the methods proposed here in conjunction with some way to quantify not just the correctness of a decision, but also the associated cost and/or reward of a decision. While some ways to assign costs to decisions were discussed, if we want to provide any evidence that this methodology is a good way to evaluate goalies in real time and not just a theoretical approach to the problem, we need to figure out exactly how switching goalies could improve a team’s chances of winning. With that in mind, the logical next step would be to make a decision based on a team’s current win probability – after all, if the team has a higher probability of winning with the backup in net than with the starter in net, we should switch goalies. Therefore, the next part of this project will be focused on creating and evaluating a win probability model that incorporates the in-game goalie evaluation techniques introduced here, and on using that model to determine when a team would be better off with the backup in net.</p>
</div>
